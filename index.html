<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sukriti Paul</title>

    <meta name="author" content="Sukriti">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sukriti Paul
                </p>
                <p>I'm a PhD student in Computer Science at the University of Maryland, College Park, specializing in computer vision and representation learning. At <span class="highlight">Prof. Tom Goldstein's Lab</span>, my research focuses on developing innovative solutions at the intersection of vision tokenization efficiency and multimodal AI systems.
                </p>
                <p>
                  Previously, I completed my Master's in Computer Science at the University of Maryland, College Park. I carry around 5 years of industry experience spanning AI, where I've consistently delivered impactful solutions—from predicting structures of 248K novel proteins at NonExomics to developing an AI diagnostic system for medical imaging at IISc that received <span class="highlight">Bill & Melinda Gates Foundation </span> funding. At American Express, I implemented data engineering solutions using billion-scale customer and merchant data across industries to boost customer engagement in our enterprise recommender system. Throughout my research journey, I've closely worked with my previous advisors <span class="highlight">Prof. Sudhakaran Prabakaran (NonExomics), Prof. Chandra Sekhar Seelamantula (IISc) and Prof. K.R. Ramakrishnan (IISc)</span>.
                </p>
                <!-- Pages Navigation -->
                <p style="text-align:center; margin-bottom: 5px;">
                  <span style="display: inline-block; background-color: rgba(46, 139, 87, 0.1); padding: 5px 15px; border-radius: 20px;">
                    <a href="index.html" style="color: #2e8b57; font-weight: bold; text-decoration: none;">Home</a> &nbsp;•&nbsp;
                    <a href="achievements.html" style="color: #2e8b57; font-weight: bold; text-decoration: none;">Experience</a> <!-- &nbsp;•&nbsp;
                    <a href="blog.html" style="color: #2e8b57; font-weight: bold; text-decoration: none;">Blog</a> -->
                  </span>
                </p>
                
                <!-- External Links -->
                <p style="text-align:center; margin-top: 8px;">
                  <a href="mailto:sukriti5@umd.edu">Email</a> &nbsp;/&nbsp;
                  <a href="utils/Sukriti_Resume.pdf">Resume</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=h8pbIOIAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/sukritipaul5">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/sukriti-paul-72a115126/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://x.com/sukritiollie">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Research</h2>
                <p>
                  My research spans multiple efficiency approaches for vision tokenizers, including adaptive token length mechanisms, quantization techniques, and optimized caching strategies. I'm interested in understanding how tokenization quality affects downstream tasks ranging from image generation to multimodal understanding. My current research focus is on flexible length image tokenisation approaches, investigating how we can reduce computational requirements while maintaining representational power. </p>

                  <p>I'm equally passionate about data composition for generative vision models. I've been a core creator of the PixelProse dataset—a massive 16M+ image collection with high-quality synthetic captions utilized by Idefics3, Janus, JanusFlow, and DeepSeek-VL2. Our work provides critical insights into how data quality and diversity shape vision-language capabilities. 
                </p>
              </td>
            </tr>
          </tbody></table>
          
          
          <!-- Relevant Coursework Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Relevant Coursework</h2>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px;width:50%;vertical-align:top">
                <ul>
                  <li>CMSC828I: Advanced Techniques in Visual Learning & Recognition</li>
                  <li>CMSC723: Graduate Natural Language Processing</li>
                  <li>CMSC848O: Seminar on Long-Context Language Models</li>
                  <li>CMSC828P: AI/ML at Scale</li>
                </ul>
              </td>
              <td style="padding:0px;width:50%;vertical-align:top">
                <ul>
                  <li>CMSC764: Advanced Numerical Optimization</li>
                  <li>CMSC838C: Advances in XR</li>
                  <li>CMSC848B: Computational Imaging</li>
                  <li>CMSC828G: Systems for Machine Learning</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          
          
          <!-- Projects Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Projects</h2>
                <!-- <p>
                  Some recent projects I've worked on. More details can be found on my <a href="https://github.com/">GitHub</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">PixelProse Power Up: Text-Focused Enhancement for Diffusion Models</h3>
                  <img src="images/PProse_Diffusion_Project.png" style="width:100%;margin-bottom:10px;" alt="PixelProse Power Up Project">
                  <p>Fine-tuning Stable Diffusion 3 Medium at 1M-image scale with extended context window capabilities, employing model and data sharding, latent caching, and distributed training optimizations to target improved text rendering in generated images.</p>
                  <p>Sukriti Paul, Vasu Singla (Project advisors: Ashwinee Panda, Micah Goldblum, Vikash Shewag, Tom Goldstein)</p>
                  <p><a href="https://github.com/sukritipaul5/PixelProse-PowerUp/tree/main">GitHub</a></p>
                </div>
              </td>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">Project 2</h3>
                  <p>Description of project 2, including the technologies used, your role, and the outcomes or impact.</p>
                  <p><a href="#">GitHub</a> | <a href="#">Demo</a></p>
                </div>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">Project 3</h3>
                  <p>Description of project 3, including the technologies used, your role, and the outcomes or impact.</p>
                  <p><a href="#">GitHub</a> | <a href="#">Demo</a></p>
                </div>
              </td>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">Project 4</h3>
                  <p>Description of project 4, including the technologies used, your role, and the outcomes or impact.</p>
                  <p><a href="#">GitHub</a> | <a href="#">Demo</a></p>
                </div>
              </td>
            </tr>
          </tbody></table> -->
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="images/Pprose_Project.png" target="_blank">
          <img src='images/Pprose_Project.png' width=100% style="cursor:pointer;" title="Click to view larger image">
        </a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.10328">
          <span class="papertitle">From Pixels to Prose: A Large Dataset of Dense Image Captions</span>
        </a>
        <br>
        <span style="color:#2e8b57;">Vasu Singla<sup>*</sup>, Kaiyu Yue<sup>*</sup></span>, <strong>Sukriti Paul</strong><sup>+</sup>, <span style="color:#2e8b57;">Reza Shirkavand<sup>+</sup>, Mayuka Jayawardhana, Alireza Ganjdanesh, Heng Huang, Abhinav Bhatele, Gowthami Somepalli, Tom Goldstein</span>
        <br>
        <a href="https://arxiv.org/abs/2406.10328" style="color:#4CAF50; font-weight:bold;">arXiv</a> /
        <a href="https://huggingface.co/datasets/tomg-group-umd/pixelprose" style="color:#4CAF50; font-weight:bold;">HF dataset</a>
        <p></p>
        <p>
        Developed a comprehensive 16M+ image dataset with rich synthetic captions, enhancing multimodal AI training through rigorous quality control and ethical safeguards while enabling significant improvements in text understanding for vision-language models.
        </p>
      </td>
    </tr>
    

    <tr style="background-color: rgba(46, 139, 87, 0.1);">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="images/PProse_Diffusion_Project.png" target="_blank">
          <img src='images/PProse_Diffusion_Project.png' width=100% style="cursor:pointer;" title="Click to view larger image">
        </a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://github.com/sukritipaul5/PixelProse-PowerUp/blob/main/README.md">
          <span class="papertitle">PixelProse Power Up: Text-Focused Enhancement for Diffusion Models</span>
        </a>
        <br>
        <strong>Sukriti Paul</strong>, 
        <span style="color:#2e8b57;">Vasu Singla (Project advisors: Ashwinee Panda, Micah Goldblum, Vikash Shewag, Tom Goldstein)</span>
        <br>
        <a href="https://github.com/sukritipaul5/PixelProse-PowerUp/blob/main/README.md" style="color:#4CAF50; font-weight:bold;">GitHub</a>
        <p></p>
        <p>
        Fine-tuning Stable Diffusion 3 Medium at 1M-image scale with extended context window capabilities, employing model and data sharding, latent caching, and distributed training optimizations to target improved text rendering in generated images.
        </p>
      </td>
    </tr>

    <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <a href="images/llamacosmos.png" target="_blank">
              <img src='images/llamacosmos.png' width=100% style="cursor:pointer;" title="Click to view larger image">
            </a>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://github.com/sukritipaul5/LlamaGen-Cosmos">
              <span class="papertitle">LlamaGen-Cosmos Training</span>
            </a>
            <br>
            <strong>Sukriti Paul</strong>
            <br>
            <a href="https://github.com/sukritipaul5/LlamaGen-Cosmos" style="color:#4CAF50; font-weight:bold;">GitHub</a>
            <p></p>
            <p>
            A distributed training implementation for class-conditional image synthesis using LlamaGen architecture with the Cosmos DI8-8 tokenizer. This framework enables efficient multi-node training on pre-cached ImageNet latents, designed for exploring autoregressive image generation model performance at scale.
            </p>
          </td>
        </tr>
        
    <tr style="background-color: rgba(46, 139, 87, 0.05);">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <a href="images/ptq.png" target="_blank">
              <img src='images/ptq.png' width=100% style="cursor:pointer;" title="Click to view larger image">
            </a>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://github.com/sukritipaul5/Cosmos-PTQ">
              <span class="papertitle">Post-Training Quantization of NVIDIA's Cosmos Image Tokenizer</span>
            </a>
            <br>
            <strong>Sukriti Paul</strong> <span style="color:#2e8b57;">(Project advisor: David Jacobs)</span>
            <br>
            <a href="https://github.com/sukritipaul5/Cosmos-PTQ" style="color:#4CAF50; font-weight:bold;">GitHub</a> /
            <a href="https://github.com/sukritipaul5/Cosmos-PTQ/blob/main/PTQ_Report.pdf" style="color:#4CAF50; font-weight:bold;">Report</a>
            <p></p>
            <p>
            Implemented PTQ techniques like logarithmic and per-tensor for the Cosmos tokenizer, showing logarithmic quantization's superior performance (25.15 dB vs 14.84 dB PSNR at 6-bit), while achieving up to 7.8× model size reduction through asymmetric encoder-decoder compression without sacrificing image fidelity.
            </p>
          </td>
        </tr>

          </tbody></table>

          <!-- Other Projects Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Other Projects</h2>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <a href="images/gene.png" target="_blank">
                  <img src='images/gene.png' width=100% style="cursor:pointer; border-radius:5px;" title="Click to view larger image">
                </a>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Research on nORFs and the Novel Proteins they Encode</span>
                <br>
                <strong>Sukriti Paul</strong>,
                <span style="color:#2e8b57;">PI & CEO: Dr. Sudhakaran Prabakaran, NonExomics</span>
                <br>
                <span style="font-style:italic; color:#666;">Funded by Illumina and AWS</span>
                <p></p>
                <p>
                  At the R&D division of a biotech startup, I develop ML frameworks for Proteogenomics and Structural Genomics data analysis. I work on diverse ML research problems associated with novel Open Reading Frames (nORFs): Structure prediction, protein clustering, subcellular localization, variant prioritization, protein-protein interactions, and the evolution of novel proteins. Under Dr. Matt Wayland, I have contributed to developing our enterprise's cloud and data infrastructure.
                </p>
                <p><span style="font-style:italic;">No Links (the proprietary algorithms, pipelines, and research ideas are confidential as per CDA.)</span></p>
              </td>
            </tr>
            
            <tr style="background-color: rgba(46, 139, 87, 0.05);">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <a href="images/wce.png" target="_blank">
                  <img src='images/wce.png' width=100% style="cursor:pointer; border-radius:5px;" title="Click to view larger image">
                </a>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Analysis of Abnormalities in Wireless Capsule Endoscopy Images</span>
                <br>
                <strong>Sukriti Paul</strong>,
                <span style="color:#2e8b57;">PI: Prof. Chandra Sekhar Seelamantula, Spectrum Lab @IISc</span>
                <br>
                <span style="font-style:italic; color:#666;">Funded by Bill & Melinda Gates Foundation, Robert Bosch Centre for Cyber Physical System</span>
                <p></p>
                <p>
                  Worked on classification, semantic segmentation, instance segmentation, clustering, and artificial image synthesis tasks for endoscopic abnormalities present in Wireless Capsule Endoscopy (WCE) images. Our team has developed an end-to-end WCE system that reduces screening time of WCE lesions from ~4 hours to ~8 minutes. We worked in collaboration with The Command Hospital Air Force Bangalore and Kasturba Medical College, Manipal.
                </p>
                <p>
                  <a href="https://drive.google.com/file/d/0B_swnsCcJGMpQWlvcm9iSzRXVDE2YmVOLXdpZHNrLTFZVzc0/view?resourcekey=0-BtsXKLYrArQ9rifu_xPGGQ" style="color:#4CAF50; font-weight:bold;">Presentation</a> /
                  <a href="https://ieeexplore.ieee.org/document/9098634" style="color:#4CAF50; font-weight:bold;">Paper</a> /
                  <a href="https://www.youtube.com/watch?v=re5JogFECzE" style="color:#4CAF50; font-weight:bold;">Video</a> /
                  <a href="https://gcgh.grandchallenges.org/grant/ai-based-diagnostic-aid-wireless-capsule-endoscopy" style="color:#4CAF50; font-weight:bold;">Grant</a> /
                  <a href="https://drive.google.com/drive/folders/1dzufhu2hEJ7sq7FQeXqaTSuA7QzAymKw" style="color:#4CAF50; font-weight:bold;">Resources</a>
                </p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <a href="images/bil.png" target="_blank">
                  <img src='images/bil.png' width=100% style="cursor:pointer; border-radius:5px;" title="Click to view larger image">
                </a>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Fast Steerable Bilateral Edge Detectors</span>
                <br>
                <strong>Sukriti Paul</strong>, Prof. Sanjay Ghosh, 
                <span style="color:#2e8b57;">PI: Prof. Chandra Sekhar Seelamantula, Spectrum Lab @IISc</span>
                <br>
                <span style="font-style:italic; color:#666;">A government-funded project on sidewalk detection</span>
                <p></p>
                <p>
                  A novel, noise-robust and computationally efficient algorithm for real-time bilateral edge detection. By integrating the concept of steerability into the design, we achieve a favorable balance between image accuracy and processing speed. Our approach builds upon Sanjay Ghosh et al.'s work on "Fast Bilateral Filtering Using Fourier Kernels," extending it with directional sensitivity for enhanced edge detection capabilities across various noise conditions while maintaining computational efficiency.
                </p>
                <p>
                  <a href="https://drive.google.com/file/d/0B8dlzfL2QMjVZzhhNUR2bEFBS00/view?resourcekey=0-qfKtjDSE2kXwZy06Zn5O2A" style="color:#4CAF50; font-weight:bold;">Presentation</a> /
                  <a href="https://drive.google.com/file/d/1X0TwHxJd_eNBsnoDOQiouZLvWdIINXc1/view" style="color:#4CAF50; font-weight:bold;">Paper</a> /
                  <a href="https://drive.google.com/file/d/0B_swnsCcJGMpZy1EeHk4T21NTTJIRDNwNHFVMkUwWWxwR2N3/view?resourcekey=0-oeZXiJ4necv_J06HX-P8kg" style="color:#4CAF50; font-weight:bold;">Report</a>
                </p>
              </td>
            </tr>
            
            <tr style="background-color: rgba(46, 139, 87, 0.05);">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <a href="images/kannadaocr.png" target="_blank">
                  <img src='images/kannadaocr.png' width=100% style="cursor:pointer; border-radius:5px;" title="Click to view larger image">
                </a>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Transliteration of Kannada Text from a Camera Captured Scene-Image on an Android Platform</span>
                <br>
                <strong>Sukriti Paul</strong>,
                <span style="color:#2e8b57;">PI: Prof. K.R. Ramakrishnan, CVAI Lab @IISc</span>
                <br>
                <span style="font-style:italic; color:#666;">Funded by IISc</span>
                <p></p>
                <p>
                  Developed a specialized pre-processing algorithm for raw textual scene images that optimizes input for OCR systems like Tesseract. Enhanced Tesseract's capabilities by training it on diverse Kannada font combinations, significantly improving recognition of Kannada script. Designed a high-performing Convolutional Neural Network for Kannada character recognition that achieved 96.8% accuracy—surpassing state-of-the-art results by approximately 2%. Implemented these advances in a practical Android application that efficiently pre-processes images and transliterates Kannada text using Tesseract tools for mobile platforms.
                </p>
                <p>
                  <a href="https://drive.google.com/file/d/0B_swnsCcJGMpYk1sSDg1TlVuX1otMzBQSUdLRUxySnpWTXdB/view?resourcekey=0-5fuOY6w11vyoDYYRg76RKQ" style="color:#4CAF50; font-weight:bold;">Report</a> /
                  <a href="https://docs.google.com/presentation/d/1hWQ2i_P38iD3Trcng4a8nVKJCEdDE7VDRAgkdhrWDhg/edit#slide=id.p1" style="color:#4CAF50; font-weight:bold;">Presentation</a> /
                  <a href="https://drive.google.com/drive/folders/0B_swnsCcJGMpamN6MHBhaWtGRW8?resourcekey=0-0MuxdMQpIi4omyqEL0tIoA" style="color:#4CAF50; font-weight:bold;">Pre-processing Code</a> /
                  <a href="https://drive.google.com/file/d/1oIsEQeIfdIqy4wMMgI8si6R92p3rw7XX/view" style="color:#4CAF50; font-weight:bold;">Poster</a>
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- Teaching Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Updates</h2>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <p><strong>Teaching Assistant</strong> for <span style="color:#2e8b57;">CMSC 250: Discrete Structures</span> at University of Maryland, College Park (Spring'25)</p>
              </td>
            </tr>
          </tbody></table>
          
  </body>
</html>          
					
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;color:#2e8b57;">
                  Design and source code from Jon Barron's website.
                  © 2025 Sukriti. All rights reserved.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
