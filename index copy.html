<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sukriti Paul</title>

    <meta name="author" content="Sukriti">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sukriti Paul
                </p>
                <p>I'm a PhD student in Computer Science at the University of Maryland, College Park, specializing in computer vision and representation learning. Advised by <span class="highlight">Prof. Tom Goldstein</span>, my research focuses on developing innovative solutions at the intersection of vision tokenization efficiency and multimodal AI systems.
                </p>
                <p>
                  Previously, I completed my Master's in Computer Science at the University of Maryland, College Park. I carry around 5 years of industry experience spanning AI, where I've consistently delivered impactful solutions—from predicting structures of 248K novel proteins at NonExomics to developing an AI diagnostic system for medical imaging at IISc that received <span class="highlight">Bill & Melinda Gates Foundation </span> funding. At American Express, I implemented data engineering solutions using billion-scale customer and merchant data across industries to boost customer engagement in our enterprise recommender system. Throughout my research journey, I've closely worked with my previous advisors <span class="highlight">Prof. Sudhakaran Prabakaran (NonExomics), Prof. Chandra Sekhar Seelamantula (IISc) and Prof. K.R. Ramakrishnan (IISc)</span>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:your.email@university.edu">Email</a> &nbsp;/&nbsp;
                  <a href="#">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Research</h2>
                <p>
                  My research spans multiple efficiency approaches for vision tokenizers, including adaptive token length mechanisms, quantization techniques, and optimized caching strategies. I'm obsessed by how tokenization quality affects downstream tasks ranging from image generation to multimodal understanding. My current research focus is on flexible length image tokenisation approaches that dynamically adapt to visual complexity, investigating how we can reduce computational requirements while maintaining representational power. </p>

                  <p>I'm equally passionate about data composition for generative vision models. I've been a core creator of the PixelProse dataset—a massive 16M+ image collection with high-quality synthetic captions utilized by Idefics3, Janus, JanusFlow, and DeepSeek-VL2. Our work provides critical insights into how data quality and diversity shape vision-language capabilities. 
                </p>
              </td>
            </tr>
          </tbody></table>
          
          
          <!-- Relevant Coursework Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Relevant Coursework</h2>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px;width:50%;vertical-align:top">
                <ul>
                  <li>CMSC828I: Advanced Techniques in Visual Learning & Recognition</li>
                  <li>CMSC723: Graduate Natural Language Processing</li>
                  <li>CMSC848O: Seminar on Long-Context Language Models</li>
                  <li>CMSC828P: AI/ML at Scale</li>
                </ul>
              </td>
              <td style="padding:0px;width:50%;vertical-align:top">
                <ul>
                  <li>CMSC764: Advanced Numerical Optimization</li>
                  <li>CMSC838C: Advances in XR</li>
                  <li>CMSC848B: Computational Imaging</li>
                  <li>CMSC828G: Systems for Machine Learning</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Publications Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Selected Publications</h2>
                <p>
                  Here are some of my recent publications. For a complete list, please see my <a href="https://scholar.google.com/">Google Scholar profile</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- Publication 1 -->
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <div style="margin-bottom:20px;">
                  <h3 style="margin:0;font-weight:bold;">Paper Title 1</h3>
                  <p style="margin:0;font-style:italic;">Authors: <strong>Sukriti</strong>, Co-author 1, Co-author 2</p>
                  <p style="margin-top:5px;color:#2e8b57;"><strong>Conference/Journal Name</strong>, Year</p>
                  <p style="margin-top:5px;">Brief description of the paper and its contributions to the field. This could include the problem addressed, the approach taken, and the key results or impact.</p>
                  <p>
                    <a href="#">Paper</a> | 
                    <a href="#">Code</a> | 
                    <a href="#">Slides</a> | 
                    <a href="#">Video</a>
                  </p>
                </div>
              </td>
            </tr>
            
            <!-- Publication 2 -->
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <div style="margin-bottom:20px;background-color:rgba(46, 139, 87, 0.05);padding:15px;border-left:3px solid #2e8b57;">
                  <h3 style="margin:0;font-weight:bold;">Paper Title 2</h3>
                  <p style="margin:0;font-style:italic;">Authors: Co-author 1, <strong>Sukriti</strong>, Co-author 2</p>
                  <p style="margin-top:5px;color:#2e8b57;"><strong>Conference/Journal Name</strong>, Year</p>
                  <p style="margin-top:5px;">Brief description of the paper and its contributions to the field. This could include the problem addressed, the approach taken, and the key results or impact.</p>
                  <p>
                    <a href="#">Paper</a> | 
                    <a href="#">Code</a> | 
                    <a href="#">Slides</a> | 
                    <a href="#">Video</a>
                  </p>
                </div>
              </td>
            </tr>
            
            <!-- Publication 3 -->
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <div>
                  <h3 style="margin:0;font-weight:bold;">Paper Title 3</h3>
                  <p style="margin:0;font-style:italic;">Authors: Co-author 1, Co-author 2, <strong>Sukriti</strong></p>
                  <p style="margin-top:5px;color:#2e8b57;"><strong>Conference/Journal Name</strong>, Year</p>
                  <p style="margin-top:5px;">Brief description of the paper and its contributions to the field. This could include the problem addressed, the approach taken, and the key results or impact.</p>
                  <p>
                    <a href="#">Paper</a> | 
                    <a href="#">Code</a> | 
                    <a href="#">Slides</a> | 
                    <a href="#">Video</a>
                  </p>
                </div>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Projects Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2 class="section-title">Projects</h2>
                <p>
                  Some recent projects I've worked on. More details can be found on my <a href="https://github.com/">GitHub</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">PixelProse Power Up: Text-Focused Enhancement for Diffusion Models</h3>
                  <img src="images/PProse_Diffusion_Project.png" style="width:100%;margin-bottom:10px;" alt="PixelProse Power Up Project">
                  <p>Fine-tuning Stable Diffusion 3 Medium at 1M-image scale with extended context window capabilities, employing model and data sharding, latent caching, and distributed training optimizations to target improved text rendering in generated images.</p>
                  <p>Sukriti Paul, Vasu Singla (Project advisors: Ashwinee Panda, Micah Goldblum, Vikash Shewag, Tom Goldstein)</p>
                  <p><a href="https://github.com/sukritipaul5/PixelProse-PowerUp/tree/main">GitHub</a></p>
                </div>
              </td>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">Project 2</h3>
                  <p>Description of project 2, including the technologies used, your role, and the outcomes or impact.</p>
                  <p><a href="#">GitHub</a> | <a href="#">Demo</a></p>
                </div>
              </td>
            </tr>
            <tr>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">Project 3</h3>
                  <p>Description of project 3, including the technologies used, your role, and the outcomes or impact.</p>
                  <p><a href="#">GitHub</a> | <a href="#">Demo</a></p>
                </div>
              </td>
              <td style="padding:16px;width:50%;vertical-align:top">
                <div style="border:1px solid #e0e0e0;border-radius:5px;padding:15px;height:100%;">
                  <h3 style="margin-top:0;color:#2e8b57;">Project 4</h3>
                  <p>Description of project 4, including the technologies used, your role, and the outcomes or impact.</p>
                  <p><a href="#">GitHub</a> | <a href="#">Demo</a></p>
                </div>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <a href="images/Pprose_Project.png" target="_blank">
          <img src='images/Pprose_Project.png' width=100% style="cursor:pointer;" title="Click to view larger image">
        </a>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2406.10328">
          <span class="papertitle">From Pixels to Prose: A Large Dataset of Dense Image Captions</span>
        </a>
        <br>
        <span style="color:#2e8b57;">Vasu Singla<sup>*</sup>, Kaiyu Yue<sup>*</sup></span>, <strong>Sukriti Paul</strong><sup>+</sup>, <span style="color:#2e8b57;">Reza Shirkavand<sup>+</sup>, Mayuka Jayawardhana, Alireza Ganjdanesh, Heng Huang, Abhinav Bhatele, Gowthami Somepalli, Tom Goldstein</span>
        <br>
        <a href="https://arxiv.org/abs/2406.10328" style="color:#4CAF50; font-weight:bold;">arXiv</a> /
        <a href="https://huggingface.co/datasets/tomg-group-umd/pixelprose" style="color:#4CAF50; font-weight:bold;">HF dataset</a>
        <p></p>
        <p>
        Developed a comprehensive 16M+ image dataset with rich synthetic captions, enhancing multimodal AI training through rigorous quality control and ethical safeguards while enabling significant improvements in text understanding for vision-language models.
        </p>
      </td>
    </tr>
    

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src='images/PProse_Diffusion_Project.png' width=100%>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://github.com/sukritipaul5/PixelProse-PowerUp/blob/main/README.md">
          <span class="papertitle">PixelProse Power Up: Text-Focused Enhancement for Diffusion Models</span>
        </a>
        <br>
        <strong>Sukriti Paul</strong>, 
        <span style="color:#2e8b57;">Vasu Singla (Project advisors: Ashwinee Panda, Micah Goldblum, Vikash Shewag, Tom Goldstein)</span>
        <br>
        <a href="https://github.com/sukritipaul5/PixelProse-PowerUp/blob/main/README.md" style="color:#4CAF50; font-weight:bold;">GitHub</a>
        <p></p>
        <p>
        Fine-tuning Stable Diffusion 3 Medium at 1M-image scale with extended context window capabilities, employing model and data sharding, latent caching, and distributed training optimizations to target improved text rendering in generated images.
        </p>
      </td>
    </tr>

    <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <a href="images/ptq.png" target="_blank">
              <img src='images/ptq.png' width=100% style="cursor:pointer;" title="Click to view larger image">
            </a>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://github.com/sukritipaul5/Cosmos-PTQ">
              <span class="papertitle">Post-Training Quantization of NVIDIA's Cosmos Image Tokenizer</span>
            </a>
            <br>
            <strong>Sukriti Paul</strong> <span style="color:#2e8b57;">(Project advisor: David Jacobs)</span>
            <br>
            <a href="https://github.com/sukritipaul5/Cosmos-PTQ" style="color:#4CAF50; font-weight:bold;">GitHub</a> /
            <a href="https://github.com/sukritipaul5/Cosmos-PTQ/blob/main/PTQ_Report.pdf" style="color:#4CAF50; font-weight:bold;">Report</a>
            <p></p>
            <p>
            Implemented PTQ techniques like logarithmic and per-tensor for the Cosmos tokenizer, showing logarithmic quantization's superior performance (25.15 dB vs 14.84 dB PSNR at 6-bit), while achieving up to 7.8× model size reduction through asymmetric encoder-decoder compression without sacrificing image fidelity.
            </p>
          </td>
        </tr>

          </tbody></table>
          
          
  </body>
</html>          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a>
								<br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a>
								<br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a>
								<br>
								<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a>
								<br>
								<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;color:#2e8b57;">
                  © 2025 Sukriti. All rights reserved.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
